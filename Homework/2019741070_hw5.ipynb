{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RPAplbirT_Jj",
        "outputId": "48c0d4ba-dd12-4c5c-89d0-1aee17b1c638"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_3 (Conv2D)           (None, 238, 238, 16)      448       \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 119, 119, 16)     0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 119, 119, 16)      0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 117, 117, 32)      4640      \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 58, 58, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 58, 58, 32)        0         \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 56, 56, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 28, 28, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 28, 28, 32)        0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 25088)             0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 512)               12845568  \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 3)                 1539      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 12,861,443\n",
            "Trainable params: 12,861,443\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/2000\n",
            "5/5 [==============================] - 3s 575ms/step - loss: 8.2479 - accuracy: 0.4240 - val_loss: 1.9741 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/2000\n",
            "5/5 [==============================] - 1s 259ms/step - loss: 1.4921 - accuracy: 0.4447 - val_loss: 1.1099 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/2000\n",
            "5/5 [==============================] - 1s 144ms/step - loss: 1.0810 - accuracy: 0.4447 - val_loss: 1.1103 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/2000\n",
            "5/5 [==============================] - 1s 149ms/step - loss: 1.0754 - accuracy: 0.4447 - val_loss: 1.1363 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/2000\n",
            "5/5 [==============================] - 1s 144ms/step - loss: 1.0186 - accuracy: 0.4484 - val_loss: 1.4165 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/2000\n",
            "5/5 [==============================] - 1s 150ms/step - loss: 0.9846 - accuracy: 0.4503 - val_loss: 1.2152 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/2000\n",
            "5/5 [==============================] - 1s 144ms/step - loss: 0.9612 - accuracy: 0.4841 - val_loss: 1.3710 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/2000\n",
            "5/5 [==============================] - 1s 146ms/step - loss: 0.9681 - accuracy: 0.4765 - val_loss: 1.2168 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/2000\n",
            "5/5 [==============================] - 1s 145ms/step - loss: 0.9629 - accuracy: 0.5047 - val_loss: 1.2121 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/2000\n",
            "5/5 [==============================] - 1s 148ms/step - loss: 0.9622 - accuracy: 0.4822 - val_loss: 1.3063 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/2000\n",
            "5/5 [==============================] - 1s 145ms/step - loss: 0.9532 - accuracy: 0.4615 - val_loss: 1.3280 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/2000\n",
            "5/5 [==============================] - 1s 145ms/step - loss: 0.9567 - accuracy: 0.4859 - val_loss: 1.2764 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/2000\n",
            "5/5 [==============================] - 1s 146ms/step - loss: 0.9567 - accuracy: 0.5141 - val_loss: 1.3032 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/2000\n",
            "5/5 [==============================] - 1s 146ms/step - loss: 0.9418 - accuracy: 0.5403 - val_loss: 1.4108 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/2000\n",
            "5/5 [==============================] - 1s 150ms/step - loss: 0.9358 - accuracy: 0.5103 - val_loss: 1.3285 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/2000\n",
            "5/5 [==============================] - 1s 148ms/step - loss: 0.9184 - accuracy: 0.5441 - val_loss: 1.3226 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/2000\n",
            "5/5 [==============================] - 1s 148ms/step - loss: 0.9228 - accuracy: 0.5310 - val_loss: 1.2898 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/2000\n",
            "5/5 [==============================] - 1s 144ms/step - loss: 0.9147 - accuracy: 0.5572 - val_loss: 1.2978 - val_accuracy: 0.0169\n",
            "Epoch 19/2000\n",
            "5/5 [==============================] - 1s 145ms/step - loss: 0.9046 - accuracy: 0.5760 - val_loss: 1.3384 - val_accuracy: 0.0281\n",
            "Epoch 20/2000\n",
            "5/5 [==============================] - 1s 159ms/step - loss: 0.9040 - accuracy: 0.5441 - val_loss: 1.3705 - val_accuracy: 0.0281\n",
            "Epoch 21/2000\n",
            "5/5 [==============================] - 1s 144ms/step - loss: 0.8945 - accuracy: 0.5553 - val_loss: 1.3315 - val_accuracy: 0.0393\n",
            "Epoch 22/2000\n",
            "5/5 [==============================] - 1s 148ms/step - loss: 0.8719 - accuracy: 0.5610 - val_loss: 1.4130 - val_accuracy: 0.0506\n",
            "Epoch 23/2000\n",
            "5/5 [==============================] - 1s 145ms/step - loss: 0.8768 - accuracy: 0.5629 - val_loss: 1.3753 - val_accuracy: 0.0674\n",
            "Epoch 24/2000\n",
            "5/5 [==============================] - 1s 146ms/step - loss: 0.8752 - accuracy: 0.5535 - val_loss: 1.4086 - val_accuracy: 0.0730\n",
            "Epoch 25/2000\n",
            "5/5 [==============================] - 1s 148ms/step - loss: 0.8550 - accuracy: 0.5741 - val_loss: 1.4251 - val_accuracy: 0.0730\n",
            "Epoch 26/2000\n",
            "5/5 [==============================] - 1s 146ms/step - loss: 0.8523 - accuracy: 0.5779 - val_loss: 1.3617 - val_accuracy: 0.0955\n",
            "Epoch 27/2000\n",
            "5/5 [==============================] - 1s 146ms/step - loss: 0.8431 - accuracy: 0.5779 - val_loss: 1.4797 - val_accuracy: 0.0787\n",
            "Epoch 28/2000\n",
            "5/5 [==============================] - 1s 147ms/step - loss: 0.8201 - accuracy: 0.5947 - val_loss: 1.3340 - val_accuracy: 0.1404\n",
            "Epoch 29/2000\n",
            "5/5 [==============================] - 1s 147ms/step - loss: 0.8615 - accuracy: 0.5872 - val_loss: 1.6136 - val_accuracy: 0.0618\n",
            "Epoch 30/2000\n",
            "5/5 [==============================] - 1s 147ms/step - loss: 0.8403 - accuracy: 0.5722 - val_loss: 1.8315 - val_accuracy: 0.0393\n",
            "Epoch 31/2000\n",
            "5/5 [==============================] - 1s 145ms/step - loss: 0.8245 - accuracy: 0.6248 - val_loss: 1.6487 - val_accuracy: 0.0730\n",
            "Epoch 32/2000\n",
            "5/5 [==============================] - 1s 146ms/step - loss: 0.7811 - accuracy: 0.6285 - val_loss: 1.7057 - val_accuracy: 0.1067\n",
            "Epoch 33/2000\n",
            "5/5 [==============================] - 1s 145ms/step - loss: 0.7530 - accuracy: 0.6548 - val_loss: 1.7314 - val_accuracy: 0.1011\n",
            "Epoch 34/2000\n",
            "5/5 [==============================] - 1s 145ms/step - loss: 0.7575 - accuracy: 0.6398 - val_loss: 1.9899 - val_accuracy: 0.0730\n",
            "Epoch 35/2000\n",
            "5/5 [==============================] - 1s 145ms/step - loss: 0.7197 - accuracy: 0.6867 - val_loss: 1.7399 - val_accuracy: 0.1011\n",
            "Epoch 36/2000\n",
            "5/5 [==============================] - 1s 150ms/step - loss: 0.7038 - accuracy: 0.6811 - val_loss: 1.8026 - val_accuracy: 0.1011\n",
            "Epoch 37/2000\n",
            "5/5 [==============================] - 1s 145ms/step - loss: 0.6745 - accuracy: 0.7205 - val_loss: 2.1290 - val_accuracy: 0.0730\n",
            "Epoch 38/2000\n",
            "5/5 [==============================] - 1s 145ms/step - loss: 0.6841 - accuracy: 0.7242 - val_loss: 1.7245 - val_accuracy: 0.1180\n",
            "Epoch 39/2000\n",
            "5/5 [==============================] - 1s 148ms/step - loss: 0.6935 - accuracy: 0.7129 - val_loss: 1.6894 - val_accuracy: 0.1236\n",
            "Epoch 40/2000\n",
            "5/5 [==============================] - 1s 146ms/step - loss: 0.6261 - accuracy: 0.7373 - val_loss: 2.1126 - val_accuracy: 0.1011\n",
            "Epoch 41/2000\n",
            "5/5 [==============================] - 1s 151ms/step - loss: 0.5924 - accuracy: 0.7505 - val_loss: 2.0004 - val_accuracy: 0.1348\n",
            "Epoch 42/2000\n",
            "5/5 [==============================] - 1s 150ms/step - loss: 0.5979 - accuracy: 0.7411 - val_loss: 2.0725 - val_accuracy: 0.1180\n",
            "Epoch 43/2000\n",
            "5/5 [==============================] - 1s 145ms/step - loss: 0.5985 - accuracy: 0.7561 - val_loss: 2.1151 - val_accuracy: 0.1067\n",
            "Epoch 44/2000\n",
            "5/5 [==============================] - 1s 146ms/step - loss: 0.5921 - accuracy: 0.7392 - val_loss: 2.5079 - val_accuracy: 0.0955\n",
            "Epoch 45/2000\n",
            "5/5 [==============================] - 1s 149ms/step - loss: 0.5365 - accuracy: 0.7936 - val_loss: 2.0722 - val_accuracy: 0.1461\n",
            "Epoch 46/2000\n",
            "5/5 [==============================] - 1s 147ms/step - loss: 0.4889 - accuracy: 0.8255 - val_loss: 2.1529 - val_accuracy: 0.1573\n",
            "Epoch 47/2000\n",
            "5/5 [==============================] - 1s 145ms/step - loss: 0.4512 - accuracy: 0.8199 - val_loss: 2.8535 - val_accuracy: 0.0562\n",
            "Epoch 48/2000\n",
            "5/5 [==============================] - 1s 147ms/step - loss: 0.4214 - accuracy: 0.8518 - val_loss: 2.4325 - val_accuracy: 0.1067\n",
            "Epoch 49/2000\n",
            "5/5 [==============================] - 1s 145ms/step - loss: 0.3949 - accuracy: 0.8537 - val_loss: 2.8480 - val_accuracy: 0.1067\n",
            "Epoch 50/2000\n",
            "5/5 [==============================] - 1s 144ms/step - loss: 0.3857 - accuracy: 0.8555 - val_loss: 2.6018 - val_accuracy: 0.1404\n",
            "Epoch 51/2000\n",
            "5/5 [==============================] - 1s 145ms/step - loss: 0.3239 - accuracy: 0.8968 - val_loss: 2.7827 - val_accuracy: 0.1798\n",
            "Epoch 52/2000\n",
            "5/5 [==============================] - 1s 146ms/step - loss: 0.3347 - accuracy: 0.8687 - val_loss: 3.1170 - val_accuracy: 0.1124\n",
            "Epoch 53/2000\n",
            "5/5 [==============================] - 1s 144ms/step - loss: 0.3094 - accuracy: 0.8743 - val_loss: 3.4470 - val_accuracy: 0.1180\n",
            "Epoch 54/2000\n",
            "5/5 [==============================] - 1s 145ms/step - loss: 0.3027 - accuracy: 0.8931 - val_loss: 3.7925 - val_accuracy: 0.0955\n",
            "Epoch 55/2000\n",
            "5/5 [==============================] - 1s 144ms/step - loss: 0.2601 - accuracy: 0.9156 - val_loss: 3.1252 - val_accuracy: 0.2135\n",
            "Epoch 56/2000\n",
            "5/5 [==============================] - 1s 147ms/step - loss: 0.2407 - accuracy: 0.9231 - val_loss: 4.0362 - val_accuracy: 0.1292\n",
            "Epoch 57/2000\n",
            "5/5 [==============================] - 1s 146ms/step - loss: 0.2303 - accuracy: 0.9062 - val_loss: 3.4639 - val_accuracy: 0.1685\n",
            "Epoch 58/2000\n",
            "5/5 [==============================] - 1s 144ms/step - loss: 0.2118 - accuracy: 0.9287 - val_loss: 3.3712 - val_accuracy: 0.1742\n",
            "Epoch 59/2000\n",
            "5/5 [==============================] - 1s 145ms/step - loss: 0.1951 - accuracy: 0.9343 - val_loss: 3.3753 - val_accuracy: 0.2079\n",
            "Epoch 60/2000\n",
            "5/5 [==============================] - 1s 146ms/step - loss: 0.1774 - accuracy: 0.9456 - val_loss: 3.5891 - val_accuracy: 0.2135\n",
            "Epoch 61/2000\n",
            "5/5 [==============================] - 1s 144ms/step - loss: 0.1436 - accuracy: 0.9606 - val_loss: 4.4951 - val_accuracy: 0.1461\n",
            "Epoch 62/2000\n",
            "5/5 [==============================] - 1s 145ms/step - loss: 0.1235 - accuracy: 0.9644 - val_loss: 4.5061 - val_accuracy: 0.1629\n",
            "Epoch 63/2000\n",
            "5/5 [==============================] - 1s 146ms/step - loss: 0.1384 - accuracy: 0.9606 - val_loss: 4.2926 - val_accuracy: 0.1798\n",
            "Epoch 64/2000\n",
            "5/5 [==============================] - 1s 149ms/step - loss: 0.1183 - accuracy: 0.9625 - val_loss: 4.8676 - val_accuracy: 0.1461\n",
            "Epoch 65/2000\n",
            "5/5 [==============================] - 1s 150ms/step - loss: 0.0965 - accuracy: 0.9756 - val_loss: 4.7796 - val_accuracy: 0.1629\n",
            "Epoch 66/2000\n",
            "5/5 [==============================] - 1s 145ms/step - loss: 0.0993 - accuracy: 0.9775 - val_loss: 4.8250 - val_accuracy: 0.1685\n",
            "Epoch 67/2000\n",
            "5/5 [==============================] - 1s 145ms/step - loss: 0.0932 - accuracy: 0.9775 - val_loss: 5.5241 - val_accuracy: 0.1404\n",
            "Epoch 68/2000\n",
            "5/5 [==============================] - 1s 146ms/step - loss: 0.0928 - accuracy: 0.9644 - val_loss: 4.7055 - val_accuracy: 0.1966\n",
            "Epoch 69/2000\n",
            "5/5 [==============================] - 1s 145ms/step - loss: 0.0802 - accuracy: 0.9850 - val_loss: 6.0196 - val_accuracy: 0.1404\n",
            "Epoch 70/2000\n",
            "5/5 [==============================] - 1s 144ms/step - loss: 0.0660 - accuracy: 0.9794 - val_loss: 5.1504 - val_accuracy: 0.1966\n",
            "Epoch 71/2000\n",
            "5/5 [==============================] - 1s 145ms/step - loss: 0.0756 - accuracy: 0.9794 - val_loss: 4.4840 - val_accuracy: 0.2247\n",
            "Epoch 72/2000\n",
            "5/5 [==============================] - 1s 152ms/step - loss: 0.0465 - accuracy: 0.9887 - val_loss: 5.0690 - val_accuracy: 0.2022\n",
            "Epoch 73/2000\n",
            "5/5 [==============================] - 1s 160ms/step - loss: 0.0562 - accuracy: 0.9850 - val_loss: 4.8264 - val_accuracy: 0.2135\n",
            "Epoch 74/2000\n",
            "5/5 [==============================] - 1s 163ms/step - loss: 0.0656 - accuracy: 0.9719 - val_loss: 5.2953 - val_accuracy: 0.1742\n",
            "Epoch 75/2000\n",
            "5/5 [==============================] - 1s 152ms/step - loss: 0.0437 - accuracy: 0.9887 - val_loss: 6.2913 - val_accuracy: 0.1180\n",
            "Epoch 76/2000\n",
            "5/5 [==============================] - 1s 152ms/step - loss: 0.0447 - accuracy: 0.9869 - val_loss: 5.7259 - val_accuracy: 0.1854\n",
            "Epoch 77/2000\n",
            "5/5 [==============================] - 1s 149ms/step - loss: 0.0520 - accuracy: 0.9869 - val_loss: 5.6019 - val_accuracy: 0.2022\n",
            "Epoch 78/2000\n",
            "5/5 [==============================] - 1s 146ms/step - loss: 0.0447 - accuracy: 0.9887 - val_loss: 6.9845 - val_accuracy: 0.1292\n",
            "Epoch 79/2000\n",
            "5/5 [==============================] - 1s 148ms/step - loss: 0.0382 - accuracy: 0.9962 - val_loss: 5.9879 - val_accuracy: 0.1685\n",
            "Epoch 80/2000\n",
            "5/5 [==============================] - 1s 144ms/step - loss: 0.0342 - accuracy: 0.9925 - val_loss: 5.0698 - val_accuracy: 0.2135\n",
            "Epoch 81/2000\n",
            "5/5 [==============================] - 1s 147ms/step - loss: 0.0454 - accuracy: 0.9887 - val_loss: 5.7002 - val_accuracy: 0.2079\n",
            "Epoch 82/2000\n",
            "5/5 [==============================] - 1s 147ms/step - loss: 0.0403 - accuracy: 0.9925 - val_loss: 5.9185 - val_accuracy: 0.2022\n",
            "Epoch 83/2000\n",
            "5/5 [==============================] - 1s 146ms/step - loss: 0.0362 - accuracy: 0.9944 - val_loss: 6.1229 - val_accuracy: 0.2135\n",
            "Epoch 84/2000\n",
            "5/5 [==============================] - 1s 146ms/step - loss: 0.0355 - accuracy: 0.9925 - val_loss: 6.1200 - val_accuracy: 0.1910\n",
            "Epoch 85/2000\n",
            "5/5 [==============================] - 1s 147ms/step - loss: 0.0394 - accuracy: 0.9869 - val_loss: 5.8179 - val_accuracy: 0.2360\n",
            "Epoch 86/2000\n",
            "5/5 [==============================] - 1s 145ms/step - loss: 0.0258 - accuracy: 0.9962 - val_loss: 5.6705 - val_accuracy: 0.2360\n",
            "Epoch 87/2000\n",
            "5/5 [==============================] - 1s 146ms/step - loss: 0.0303 - accuracy: 0.9906 - val_loss: 5.4834 - val_accuracy: 0.2472\n",
            "Epoch 88/2000\n",
            "5/5 [==============================] - 1s 146ms/step - loss: 0.0204 - accuracy: 0.9981 - val_loss: 6.1022 - val_accuracy: 0.2247\n",
            "Epoch 89/2000\n",
            "5/5 [==============================] - 1s 148ms/step - loss: 0.0258 - accuracy: 0.9887 - val_loss: 6.9876 - val_accuracy: 0.1685\n",
            "Epoch 90/2000\n",
            "5/5 [==============================] - 1s 149ms/step - loss: 0.0261 - accuracy: 0.9944 - val_loss: 6.7751 - val_accuracy: 0.1573\n",
            "Epoch 91/2000\n",
            "5/5 [==============================] - 1s 147ms/step - loss: 0.0289 - accuracy: 0.9962 - val_loss: 6.7338 - val_accuracy: 0.1742\n",
            "Epoch 92/2000\n",
            "5/5 [==============================] - 1s 145ms/step - loss: 0.0182 - accuracy: 0.9981 - val_loss: 6.6558 - val_accuracy: 0.1798\n",
            "Epoch 93/2000\n",
            "5/5 [==============================] - 1s 147ms/step - loss: 0.0300 - accuracy: 0.9962 - val_loss: 6.1932 - val_accuracy: 0.2191\n",
            "Epoch 94/2000\n",
            "5/5 [==============================] - 1s 145ms/step - loss: 0.0327 - accuracy: 0.9906 - val_loss: 6.1691 - val_accuracy: 0.2360\n",
            "Epoch 95/2000\n",
            "5/5 [==============================] - 1s 145ms/step - loss: 0.0169 - accuracy: 0.9962 - val_loss: 6.2922 - val_accuracy: 0.2303\n",
            "Epoch 96/2000\n",
            "5/5 [==============================] - 1s 146ms/step - loss: 0.0221 - accuracy: 0.9944 - val_loss: 6.4235 - val_accuracy: 0.2135\n",
            "Epoch 97/2000\n",
            "5/5 [==============================] - 1s 148ms/step - loss: 0.0297 - accuracy: 0.9906 - val_loss: 7.2294 - val_accuracy: 0.1742\n",
            "Epoch 98/2000\n",
            "5/5 [==============================] - 1s 146ms/step - loss: 0.0226 - accuracy: 0.9944 - val_loss: 7.0198 - val_accuracy: 0.1798\n",
            "Epoch 99/2000\n",
            "5/5 [==============================] - 1s 146ms/step - loss: 0.0200 - accuracy: 0.9944 - val_loss: 6.0422 - val_accuracy: 0.2079\n",
            "Epoch 100/2000\n",
            "5/5 [==============================] - 1s 147ms/step - loss: 0.0225 - accuracy: 0.9944 - val_loss: 5.5777 - val_accuracy: 0.2472\n",
            "Epoch 101/2000\n",
            "5/5 [==============================] - 1s 146ms/step - loss: 0.0230 - accuracy: 0.9906 - val_loss: 6.5667 - val_accuracy: 0.1854\n",
            "Epoch 102/2000\n",
            "5/5 [==============================] - 1s 145ms/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 7.0058 - val_accuracy: 0.1629\n",
            "Epoch 103/2000\n",
            "5/5 [==============================] - 1s 146ms/step - loss: 0.0232 - accuracy: 0.9944 - val_loss: 6.8248 - val_accuracy: 0.2022\n",
            "Epoch 104/2000\n",
            "5/5 [==============================] - 1s 146ms/step - loss: 0.0232 - accuracy: 0.9925 - val_loss: 7.1327 - val_accuracy: 0.1854\n",
            "Epoch 105/2000\n",
            "5/5 [==============================] - 1s 146ms/step - loss: 0.0340 - accuracy: 0.9887 - val_loss: 7.1659 - val_accuracy: 0.1742\n",
            "Epoch 106/2000\n",
            "5/5 [==============================] - 1s 147ms/step - loss: 0.0283 - accuracy: 0.9944 - val_loss: 7.0903 - val_accuracy: 0.1685\n",
            "Epoch 107/2000\n",
            "5/5 [==============================] - 1s 145ms/step - loss: 0.0178 - accuracy: 0.9962 - val_loss: 6.3170 - val_accuracy: 0.1798\n",
            "Epoch 108/2000\n",
            "5/5 [==============================] - 1s 149ms/step - loss: 0.0180 - accuracy: 0.9944 - val_loss: 8.0036 - val_accuracy: 0.1404\n",
            "Epoch 109/2000\n",
            "5/5 [==============================] - 1s 146ms/step - loss: 0.0146 - accuracy: 0.9962 - val_loss: 8.6281 - val_accuracy: 0.1404\n",
            "Epoch 110/2000\n",
            "5/5 [==============================] - 1s 151ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 8.0810 - val_accuracy: 0.1573\n",
            "Epoch 111/2000\n",
            "5/5 [==============================] - 1s 147ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 8.2959 - val_accuracy: 0.1573\n",
            "Epoch 112/2000\n",
            "5/5 [==============================] - 1s 148ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 8.4134 - val_accuracy: 0.1742\n",
            "Epoch 113/2000\n",
            "5/5 [==============================] - 1s 147ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 8.5458 - val_accuracy: 0.1742\n",
            "Epoch 114/2000\n",
            "5/5 [==============================] - 1s 144ms/step - loss: 0.0135 - accuracy: 0.9944 - val_loss: 7.4097 - val_accuracy: 0.2079\n",
            "Epoch 115/2000\n",
            "5/5 [==============================] - 1s 147ms/step - loss: 0.0087 - accuracy: 0.9962 - val_loss: 7.2956 - val_accuracy: 0.2022\n",
            "Epoch 116/2000\n",
            "5/5 [==============================] - 1s 145ms/step - loss: 0.0079 - accuracy: 0.9981 - val_loss: 7.9672 - val_accuracy: 0.1629\n",
            "Epoch 117/2000\n",
            "5/5 [==============================] - 1s 146ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 8.5369 - val_accuracy: 0.1517\n",
            "Epoch 118/2000\n",
            "5/5 [==============================] - 1s 148ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 8.6336 - val_accuracy: 0.1573\n",
            "Epoch 119/2000\n",
            "5/5 [==============================] - 1s 149ms/step - loss: 0.0073 - accuracy: 0.9981 - val_loss: 8.3622 - val_accuracy: 0.1573\n",
            "Epoch 120/2000\n",
            "5/5 [==============================] - 1s 146ms/step - loss: 0.0090 - accuracy: 0.9981 - val_loss: 7.6784 - val_accuracy: 0.1854\n",
            "Epoch 121/2000\n",
            "5/5 [==============================] - 1s 147ms/step - loss: 0.0157 - accuracy: 0.9962 - val_loss: 6.9077 - val_accuracy: 0.2191\n",
            "Epoch 122/2000\n",
            "5/5 [==============================] - 1s 145ms/step - loss: 0.0079 - accuracy: 0.9981 - val_loss: 7.0689 - val_accuracy: 0.2135\n",
            "Epoch 123/2000\n",
            "5/5 [==============================] - 1s 148ms/step - loss: 0.0110 - accuracy: 0.9981 - val_loss: 7.3850 - val_accuracy: 0.1966\n",
            "Epoch 124/2000\n",
            "5/5 [==============================] - 1s 146ms/step - loss: 0.0122 - accuracy: 0.9944 - val_loss: 7.3903 - val_accuracy: 0.1910\n",
            "Epoch 125/2000\n",
            "5/5 [==============================] - 1s 148ms/step - loss: 0.0076 - accuracy: 0.9981 - val_loss: 7.5011 - val_accuracy: 0.1742\n",
            "Epoch 126/2000\n",
            "5/5 [==============================] - 1s 150ms/step - loss: 0.0161 - accuracy: 0.9944 - val_loss: 7.4498 - val_accuracy: 0.1910\n",
            "Epoch 127/2000\n",
            "5/5 [==============================] - 1s 146ms/step - loss: 0.0155 - accuracy: 0.9962 - val_loss: 6.8357 - val_accuracy: 0.2528\n",
            "Epoch 128/2000\n",
            "5/5 [==============================] - 1s 146ms/step - loss: 0.0088 - accuracy: 0.9981 - val_loss: 6.9835 - val_accuracy: 0.2360\n",
            "Epoch 129/2000\n",
            "5/5 [==============================] - 1s 148ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 7.4053 - val_accuracy: 0.2247\n",
            "Epoch 130/2000\n",
            "5/5 [==============================] - 1s 149ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 7.9111 - val_accuracy: 0.2022\n",
            "Epoch 131/2000\n",
            "5/5 [==============================] - 1s 147ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 8.2652 - val_accuracy: 0.1966\n",
            "Epoch 132/2000\n",
            "5/5 [==============================] - 1s 147ms/step - loss: 0.0112 - accuracy: 0.9962 - val_loss: 7.7877 - val_accuracy: 0.2135\n",
            "Epoch 133/2000\n",
            "5/5 [==============================] - 1s 146ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 7.1683 - val_accuracy: 0.2247\n",
            "Epoch 134/2000\n",
            "5/5 [==============================] - 1s 148ms/step - loss: 0.0107 - accuracy: 0.9981 - val_loss: 6.8738 - val_accuracy: 0.2360\n",
            "Epoch 135/2000\n",
            "5/5 [==============================] - 1s 145ms/step - loss: 0.0073 - accuracy: 0.9981 - val_loss: 7.2430 - val_accuracy: 0.2022\n",
            "Epoch 136/2000\n",
            "5/5 [==============================] - 1s 147ms/step - loss: 0.0060 - accuracy: 0.9981 - val_loss: 7.6332 - val_accuracy: 0.2079\n",
            "Epoch 137/2000\n",
            "5/5 [==============================] - 1s 150ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 7.3823 - val_accuracy: 0.2191\n",
            "Epoch 138/2000\n",
            "5/5 [==============================] - 1s 147ms/step - loss: 0.0070 - accuracy: 0.9981 - val_loss: 7.3915 - val_accuracy: 0.2247\n",
            "Epoch 139/2000\n",
            "5/5 [==============================] - 1s 156ms/step - loss: 0.0248 - accuracy: 0.9962 - val_loss: 7.9932 - val_accuracy: 0.1798\n",
            "Epoch 140/2000\n",
            "5/5 [==============================] - 1s 145ms/step - loss: 0.0117 - accuracy: 0.9944 - val_loss: 8.6426 - val_accuracy: 0.1742\n",
            "Epoch 141/2000\n",
            "5/5 [==============================] - 1s 153ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 8.7442 - val_accuracy: 0.1629\n",
            "Epoch 142/2000\n",
            "5/5 [==============================] - 1s 145ms/step - loss: 0.0075 - accuracy: 0.9981 - val_loss: 8.1796 - val_accuracy: 0.1798\n",
            "Epoch 143/2000\n",
            "5/5 [==============================] - 1s 146ms/step - loss: 0.0098 - accuracy: 0.9944 - val_loss: 7.8427 - val_accuracy: 0.1966\n",
            "Epoch 144/2000\n",
            "5/5 [==============================] - 1s 147ms/step - loss: 0.0046 - accuracy: 0.9981 - val_loss: 7.9213 - val_accuracy: 0.2022\n",
            "Epoch 145/2000\n",
            "5/5 [==============================] - 1s 145ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 8.0436 - val_accuracy: 0.1966\n",
            "Epoch 146/2000\n",
            "5/5 [==============================] - 1s 148ms/step - loss: 0.0051 - accuracy: 0.9981 - val_loss: 8.5660 - val_accuracy: 0.1854\n",
            "Epoch 147/2000\n",
            "5/5 [==============================] - 1s 148ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 9.0931 - val_accuracy: 0.1742\n",
            "Epoch 148/2000\n",
            "5/5 [==============================] - 1s 146ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 9.4516 - val_accuracy: 0.1629\n",
            "Epoch 149/2000\n",
            "5/5 [==============================] - 1s 149ms/step - loss: 0.0084 - accuracy: 0.9981 - val_loss: 8.6236 - val_accuracy: 0.1742\n",
            "Epoch 150/2000\n",
            "5/5 [==============================] - 1s 147ms/step - loss: 0.0061 - accuracy: 0.9981 - val_loss: 8.2126 - val_accuracy: 0.2079\n",
            "Epoch 151/2000\n",
            "5/5 [==============================] - 1s 146ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 8.3938 - val_accuracy: 0.1966\n",
            "Epoch 152/2000\n",
            "5/5 [==============================] - 1s 155ms/step - loss: 0.0049 - accuracy: 0.9981 - val_loss: 9.1550 - val_accuracy: 0.1685\n",
            "Epoch 153/2000\n",
            "5/5 [==============================] - 1s 147ms/step - loss: 0.0070 - accuracy: 0.9981 - val_loss: 9.5396 - val_accuracy: 0.1573\n",
            "Epoch 154/2000\n",
            "5/5 [==============================] - 1s 149ms/step - loss: 0.0106 - accuracy: 0.9944 - val_loss: 9.5343 - val_accuracy: 0.1742\n",
            "Epoch 155/2000\n",
            "5/5 [==============================] - 1s 149ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 9.2948 - val_accuracy: 0.1742\n",
            "Epoch 156/2000\n",
            "5/5 [==============================] - 1s 147ms/step - loss: 0.0036 - accuracy: 0.9981 - val_loss: 9.1572 - val_accuracy: 0.1854\n",
            "Epoch 157/2000\n",
            "5/5 [==============================] - 1s 147ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 8.8154 - val_accuracy: 0.1910\n",
            "Epoch 158/2000\n",
            "5/5 [==============================] - 1s 146ms/step - loss: 0.0081 - accuracy: 0.9981 - val_loss: 7.3648 - val_accuracy: 0.2360\n",
            "Epoch 159/2000\n",
            "5/5 [==============================] - 1s 146ms/step - loss: 0.0074 - accuracy: 0.9981 - val_loss: 8.0431 - val_accuracy: 0.1966\n",
            "Epoch 160/2000\n",
            "5/5 [==============================] - 1s 148ms/step - loss: 0.0116 - accuracy: 0.9962 - val_loss: 11.2089 - val_accuracy: 0.1011\n",
            "Epoch 161/2000\n",
            "5/5 [==============================] - 1s 146ms/step - loss: 0.0306 - accuracy: 0.9887 - val_loss: 6.4787 - val_accuracy: 0.2135\n",
            "Epoch 162/2000\n",
            "5/5 [==============================] - 1s 145ms/step - loss: 0.0273 - accuracy: 0.9962 - val_loss: 6.7434 - val_accuracy: 0.1573\n",
            "Epoch 163/2000\n",
            "5/5 [==============================] - 1s 150ms/step - loss: 0.0283 - accuracy: 0.9869 - val_loss: 7.2902 - val_accuracy: 0.1573\n",
            "Epoch 164/2000\n",
            "5/5 [==============================] - 1s 146ms/step - loss: 0.0295 - accuracy: 0.9925 - val_loss: 5.9220 - val_accuracy: 0.2135\n",
            "Epoch 165/2000\n",
            "5/5 [==============================] - 1s 146ms/step - loss: 0.0134 - accuracy: 0.9981 - val_loss: 5.4128 - val_accuracy: 0.2640\n",
            "Epoch 166/2000\n",
            "5/5 [==============================] - 1s 150ms/step - loss: 0.0204 - accuracy: 0.9944 - val_loss: 6.6366 - val_accuracy: 0.1629\n",
            "Epoch 167/2000\n",
            "5/5 [==============================] - 1s 148ms/step - loss: 0.0199 - accuracy: 0.9925 - val_loss: 7.8741 - val_accuracy: 0.1236\n",
            "Epoch 168/2000\n",
            "5/5 [==============================] - 1s 145ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 7.9874 - val_accuracy: 0.1348\n",
            "Epoch 169/2000\n",
            "5/5 [==============================] - 1s 146ms/step - loss: 0.0097 - accuracy: 0.9981 - val_loss: 7.9063 - val_accuracy: 0.1461\n",
            "Epoch 170/2000\n",
            "5/5 [==============================] - 1s 143ms/step - loss: 0.0092 - accuracy: 0.9981 - val_loss: 7.8151 - val_accuracy: 0.1517\n",
            "Epoch 171/2000\n",
            "5/5 [==============================] - 1s 146ms/step - loss: 0.0153 - accuracy: 0.9944 - val_loss: 7.2745 - val_accuracy: 0.1685\n",
            "Epoch 172/2000\n",
            "5/5 [==============================] - 1s 146ms/step - loss: 0.0187 - accuracy: 0.9981 - val_loss: 7.0528 - val_accuracy: 0.2022\n",
            "Epoch 173/2000\n",
            "5/5 [==============================] - 1s 147ms/step - loss: 0.0046 - accuracy: 0.9981 - val_loss: 7.3098 - val_accuracy: 0.2247\n",
            "Epoch 174/2000\n",
            "5/5 [==============================] - 1s 152ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 7.9265 - val_accuracy: 0.2135\n",
            "Epoch 175/2000\n",
            "5/5 [==============================] - 1s 147ms/step - loss: 0.0108 - accuracy: 0.9962 - val_loss: 8.1394 - val_accuracy: 0.2079\n",
            "Epoch 176/2000\n",
            "5/5 [==============================] - 1s 148ms/step - loss: 0.0097 - accuracy: 0.9981 - val_loss: 7.0524 - val_accuracy: 0.2303\n",
            "Epoch 177/2000\n",
            "5/5 [==============================] - 1s 149ms/step - loss: 0.0083 - accuracy: 0.9962 - val_loss: 6.3654 - val_accuracy: 0.2640\n",
            "Epoch 178/2000\n",
            "5/5 [==============================] - 1s 146ms/step - loss: 0.0146 - accuracy: 0.9944 - val_loss: 7.0022 - val_accuracy: 0.1910\n",
            "Epoch 179/2000\n",
            "5/5 [==============================] - 1s 147ms/step - loss: 0.0068 - accuracy: 0.9981 - val_loss: 7.6672 - val_accuracy: 0.1573\n",
            "Epoch 180/2000\n",
            "5/5 [==============================] - 1s 147ms/step - loss: 0.0112 - accuracy: 0.9962 - val_loss: 8.1863 - val_accuracy: 0.1292\n",
            "Epoch 181/2000\n",
            "5/5 [==============================] - 1s 147ms/step - loss: 0.0051 - accuracy: 0.9981 - val_loss: 8.2607 - val_accuracy: 0.1236\n",
            "Epoch 182/2000\n",
            "5/5 [==============================] - 1s 149ms/step - loss: 0.0068 - accuracy: 0.9962 - val_loss: 8.0615 - val_accuracy: 0.1404\n",
            "Epoch 183/2000\n",
            "5/5 [==============================] - 1s 144ms/step - loss: 0.0076 - accuracy: 0.9962 - val_loss: 8.5331 - val_accuracy: 0.1348\n",
            "Epoch 184/2000\n",
            "5/5 [==============================] - 1s 148ms/step - loss: 0.0077 - accuracy: 0.9962 - val_loss: 9.7034 - val_accuracy: 0.1236\n",
            "Epoch 185/2000\n",
            "5/5 [==============================] - 1s 147ms/step - loss: 0.0057 - accuracy: 0.9981 - val_loss: 9.9786 - val_accuracy: 0.1292\n",
            "Epoch 186/2000\n",
            "5/5 [==============================] - 1s 145ms/step - loss: 0.0082 - accuracy: 0.9981 - val_loss: 9.3764 - val_accuracy: 0.1404\n",
            "Epoch 187/2000\n",
            "5/5 [==============================] - 1s 145ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 9.0398 - val_accuracy: 0.1517\n",
            "Epoch 188/2000\n",
            "5/5 [==============================] - 1s 146ms/step - loss: 0.0114 - accuracy: 0.9944 - val_loss: 7.7775 - val_accuracy: 0.2022\n",
            "Epoch 189/2000\n",
            "5/5 [==============================] - 1s 148ms/step - loss: 0.0060 - accuracy: 0.9981 - val_loss: 7.0377 - val_accuracy: 0.2472\n",
            "Epoch 190/2000\n",
            "5/5 [==============================] - 1s 148ms/step - loss: 0.0075 - accuracy: 0.9981 - val_loss: 6.8365 - val_accuracy: 0.2416\n",
            "Epoch 191/2000\n",
            "5/5 [==============================] - 1s 149ms/step - loss: 0.0190 - accuracy: 0.9944 - val_loss: 7.4178 - val_accuracy: 0.2191\n",
            "Epoch 192/2000\n",
            "5/5 [==============================] - 1s 148ms/step - loss: 0.0056 - accuracy: 0.9981 - val_loss: 9.0503 - val_accuracy: 0.1573\n",
            "Epoch 193/2000\n",
            "5/5 [==============================] - 1s 146ms/step - loss: 0.0058 - accuracy: 0.9981 - val_loss: 9.7036 - val_accuracy: 0.1236\n",
            "Epoch 194/2000\n",
            "5/5 [==============================] - 1s 152ms/step - loss: 0.0077 - accuracy: 0.9981 - val_loss: 8.4797 - val_accuracy: 0.1404\n",
            "Epoch 195/2000\n",
            "5/5 [==============================] - 1s 144ms/step - loss: 0.0097 - accuracy: 0.9962 - val_loss: 7.5219 - val_accuracy: 0.1966\n",
            "Epoch 196/2000\n",
            "5/5 [==============================] - 1s 157ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 7.0500 - val_accuracy: 0.2191\n",
            "Epoch 197/2000\n",
            "5/5 [==============================] - 1s 147ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 7.1443 - val_accuracy: 0.2247\n",
            "Epoch 198/2000\n",
            "5/5 [==============================] - 1s 144ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 7.1286 - val_accuracy: 0.2303\n",
            "Epoch 199/2000\n",
            "5/5 [==============================] - 1s 144ms/step - loss: 0.0096 - accuracy: 0.9962 - val_loss: 7.0851 - val_accuracy: 0.2303\n",
            "Epoch 200/2000\n",
            "5/5 [==============================] - 1s 148ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 7.5005 - val_accuracy: 0.2416\n",
            "Epoch 201/2000\n",
            "5/5 [==============================] - 1s 148ms/step - loss: 0.0078 - accuracy: 0.9962 - val_loss: 6.7663 - val_accuracy: 0.2640\n",
            "Epoch 202/2000\n",
            "5/5 [==============================] - 1s 149ms/step - loss: 0.0079 - accuracy: 0.9981 - val_loss: 7.7416 - val_accuracy: 0.2079\n",
            "4/4 [==============================] - 0s 18ms/step\n",
            "<class 'numpy.ndarray'>\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import google.colab.drive as drive\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from PIL import Image\n",
        "import fnmatch\n",
        "import os\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "def fileread(dir, pix):\n",
        "  cnt=0\n",
        "  for filename in os.listdir(dir):\n",
        "    if fnmatch.fnmatch(filename, '*.jpg'):\n",
        "      im = Image.open(dir+'/'+filename)\n",
        "      pix.append(np.array(im))\n",
        "      cnt = cnt+1\n",
        "  return pix, cnt\n",
        "\n",
        "def list_replace(test_list,num, word) :\n",
        "  test_list =list(test_list)\n",
        "  for index, item in enumerate(test_list):\n",
        "    if item == num:\n",
        "        test_list[index] = word\n",
        "  return test_list\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "base_dir = './drive/MyDrive/Colab Notebooks/data/hw5_dataset'\n",
        "\n",
        "test_adidas_dir = './drive/MyDrive/Colab Notebooks/data/hw5_dataset/test/adidas'\n",
        "test_converse_dir = './drive/MyDrive/Colab Notebooks/data/hw5_dataset/test/converse'\n",
        "test_nike_dir = './drive/MyDrive/Colab Notebooks/data/hw5_dataset/test/nike'\n",
        "\n",
        "train_adidas_dir = './drive/MyDrive/Colab Notebooks/data/hw5_dataset/train/adidas'\n",
        "train_converse_dir = './drive/MyDrive/Colab Notebooks/data/hw5_dataset/train/converse'\n",
        "train_nike_dir = './drive/MyDrive/Colab Notebooks/data/hw5_dataset/train/nike'\n",
        "\n",
        "x_test_adidas = []\n",
        "x_test_converse = []\n",
        "x_test_nike = []\n",
        "\n",
        "x_train_adidas = []\n",
        "x_train_converse = []\n",
        "x_train_nike = []\n",
        "\n",
        "x_train_adidas, adidas_train_len = fileread(train_adidas_dir, x_train_adidas)\n",
        "x_train_converse, converse_train_len = fileread(train_converse_dir, x_train_converse)\n",
        "x_train_nike, nike_train_len = fileread(train_nike_dir, x_train_nike)\n",
        "\n",
        "x_test_adidas, adidas_test_len = fileread(test_adidas_dir, x_test_adidas)\n",
        "x_test_converse, converse_test_len = fileread(test_converse_dir, x_test_converse)\n",
        "x_test_nike, nike_test_len = fileread(test_nike_dir, x_test_nike)\n",
        "\n",
        "X_test = np.array(x_test_adidas + x_test_converse + x_test_nike)\n",
        "X_test = X_test.reshape(X_test.shape[0], 240, 240, 3)\n",
        "\n",
        "X_train = np.array(x_train_adidas + x_train_converse + x_train_nike)\n",
        "X_train = X_train.reshape(X_train.shape[0], 240, 240, 3)\n",
        "\n",
        "a1 = [0 for i in range(adidas_train_len)]\n",
        "a2 = [1 for i in range(converse_train_len)]\n",
        "a3 = [2 for i in range(nike_train_len)]\n",
        "\n",
        "b1 = [0 for i in range(adidas_test_len)]\n",
        "b2 = [1 for i in range(converse_test_len)]\n",
        "b3 = [2 for i in range(nike_test_len)]\n",
        "\n",
        "y_train = np.array(a1+a2+a3)\n",
        "y_test = np.array(b1+b2+b3)\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_train = X_train / 255\n",
        "X_test = X_test.astype('float32')\n",
        "X_test = X_test / 255\n",
        "\n",
        "y_train = to_categorical(y_train, 3)\n",
        "y_test = to_categorical(y_test, 3)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(16, kernel_size = (3, 3), input_shape = (240, 240, 3), activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation = 'relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(3, activation = 'softmax'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "\n",
        "early_stopping_callback = EarlyStopping(monitor = 'val_loss', patience = 200)\n",
        "modelpath = './drive/MyDrive/Colab Notebooks/data/model/samsung/assignment4_best_model.hdf5'\n",
        "checkpointer = ModelCheckpoint(filepath=modelpath, monitor = 'val_loss', verbose = 0, save_best_only = True)\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs = 2000, batch_size = 128, validation_split = 0.25, callbacks =[early_stopping_callback, checkpointer])\n",
        "\n",
        "pred = model.predict(X_test)\n",
        "pred_labels = np.argmax(pred, axis = 1)\n",
        "print(type(pred_labels))\n",
        "\n",
        "pred_labels = list_replace(pred_labels, 0, 'adidas')\n",
        "pred_labels = list_replace(pred_labels, 1, 'converse')\n",
        "pred_labels = list_replace(pred_labels, 2, 'nike')\n",
        "\n",
        "y_test = np.argmax(y_test, axis = 1)\n",
        "\n",
        "y_test = list_replace(y_test, 0, 'adidas')\n",
        "y_test = list_replace(y_test, 1, 'converse')\n",
        "y_test = list_replace(y_test, 2, 'nike')\n",
        "\n",
        "cf_matrix = confusion_matrix(y_test, pred_labels)\n",
        "\n",
        "LABELS = ['adidas', 'converse', 'nike']\n",
        "\n",
        "plt.figure(figsize = (10,10))\n",
        "sns.heatmap(cf_matrix, annot = True, xticklabels = LABELS, yticklabels = LABELS, linewidth = 0.5 )\n",
        "plt.show()"
      ]
    }
  ]
}